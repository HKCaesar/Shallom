{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_classes import Data\n",
    "import util as ut\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten,Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "import warnings\n",
    "import logging\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "random_state = 1\n",
    "np.random.seed(random_state)\n",
    "random.seed(random_state)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='WN18'\n",
    "kg_root = 'KGs/'+dataset+'/'\n",
    "dataset=Data(kg_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=[]\n",
    "x=[]\n",
    "\n",
    "entitiy_idx=dict()\n",
    "\n",
    "sub_obj_pairs= dataset.get_entity_pairs_with_predicates(dataset.train_data)\n",
    "for s_o_pair, predicates in sub_obj_pairs.items():\n",
    "    s,o=s_o_pair\n",
    "    entitiy_idx.setdefault(s, len(entitiy_idx))\n",
    "    entitiy_idx.setdefault(o, len(entitiy_idx))\n",
    "    x.append([entitiy_idx[s],entitiy_idx[o]])\n",
    "    y.append(list(predicates))\n",
    "x=np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(x)\n",
    "binarizer=MultiLabelBinarizer()\n",
    "y=binarizer.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 2, 100)            4094300   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               60300     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 18)                5418      \n",
      "=================================================================\n",
      "Total params: 4,160,018\n",
      "Trainable params: 4,160,018\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim=100\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(entitiy_idx), embedding_dim, input_length=2,activity_regularizer=l2(0.1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(.1))\n",
    "model.add(Dense(embedding_dim*3, activation='relu',activity_regularizer=l2(0.1)))\n",
    "model.add(Dropout(.1))\n",
    "model.add(Dense(y.shape[1], activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 141165 samples\n",
      "Epoch 1/50\n",
      "141165/141165 [==============================] - 6s 45us/sample - loss: 2.3466 - accuracy: 0.4078\n",
      "Epoch 2/50\n",
      "141165/141165 [==============================] - 6s 40us/sample - loss: 1.3023 - accuracy: 0.7465\n",
      "Epoch 3/50\n",
      "141165/141165 [==============================] - 6s 41us/sample - loss: 0.7963 - accuracy: 0.8701\n",
      "Epoch 4/50\n",
      "141165/141165 [==============================] - 6s 45us/sample - loss: 0.5909 - accuracy: 0.9184\n",
      "Epoch 5/50\n",
      "141165/141165 [==============================] - 6s 41us/sample - loss: 0.4782 - accuracy: 0.9409\n",
      "Epoch 6/50\n",
      "141165/141165 [==============================] - 7s 47us/sample - loss: 0.4062 - accuracy: 0.9540\n",
      "Epoch 7/50\n",
      "141165/141165 [==============================] - 6s 40us/sample - loss: 0.3560 - accuracy: 0.9603\n",
      "Epoch 8/50\n",
      "141165/141165 [==============================] - 7s 47us/sample - loss: 0.3182 - accuracy: 0.9658\n",
      "Epoch 9/50\n",
      "141165/141165 [==============================] - 6s 43us/sample - loss: 0.2892 - accuracy: 0.9700\n",
      "Epoch 10/50\n",
      "141165/141165 [==============================] - 7s 48us/sample - loss: 0.2645 - accuracy: 0.9742\n",
      "Epoch 11/50\n",
      "141165/141165 [==============================] - 8s 57us/sample - loss: 0.2436 - accuracy: 0.9777\n",
      "Epoch 12/50\n",
      "141165/141165 [==============================] - 6s 44us/sample - loss: 0.2264 - accuracy: 0.9817\n",
      "Epoch 13/50\n",
      "141165/141165 [==============================] - 6s 43us/sample - loss: 0.2107 - accuracy: 0.9859\n",
      "Epoch 14/50\n",
      "141165/141165 [==============================] - 6s 42us/sample - loss: 0.1961 - accuracy: 0.9891\n",
      "Epoch 15/50\n",
      "141165/141165 [==============================] - 6s 42us/sample - loss: 0.1833 - accuracy: 0.9915\n",
      "Epoch 16/50\n",
      "141165/141165 [==============================] - 6s 43us/sample - loss: 0.1723 - accuracy: 0.9928\n",
      "Epoch 17/50\n",
      "141165/141165 [==============================] - 6s 43us/sample - loss: 0.1634 - accuracy: 0.9933\n",
      "Epoch 18/50\n",
      "141165/141165 [==============================] - 6s 41us/sample - loss: 0.1557 - accuracy: 0.9939\n",
      "Epoch 19/50\n",
      "141165/141165 [==============================] - 6s 41us/sample - loss: 0.1480 - accuracy: 0.9950\n",
      "Epoch 20/50\n",
      "141165/141165 [==============================] - 6s 41us/sample - loss: 0.1406 - accuracy: 0.9958\n",
      "Epoch 21/50\n",
      "141165/141165 [==============================] - 6s 42us/sample - loss: 0.1352 - accuracy: 0.9956\n",
      "Epoch 22/50\n",
      "141165/141165 [==============================] - 6s 43us/sample - loss: 0.1301 - accuracy: 0.9960\n",
      "Epoch 23/50\n",
      "141165/141165 [==============================] - 6s 42us/sample - loss: 0.1258 - accuracy: 0.9957\n",
      "Epoch 24/50\n",
      "141165/141165 [==============================] - 6s 45us/sample - loss: 0.1200 - accuracy: 0.9964\n",
      "Epoch 25/50\n",
      "141165/141165 [==============================] - 7s 47us/sample - loss: 0.1158 - accuracy: 0.9964\n",
      "Epoch 26/50\n",
      "141165/141165 [==============================] - 6s 39us/sample - loss: 0.1120 - accuracy: 0.9963\n",
      "Epoch 27/50\n",
      "141165/141165 [==============================] - 6s 40us/sample - loss: 0.1099 - accuracy: 0.9961\n",
      "Epoch 28/50\n",
      "141165/141165 [==============================] - 6s 40us/sample - loss: 0.1059 - accuracy: 0.9965\n",
      "Epoch 29/50\n",
      "141165/141165 [==============================] - 6s 41us/sample - loss: 0.1039 - accuracy: 0.9962\n",
      "Epoch 30/50\n",
      "141165/141165 [==============================] - 6s 44us/sample - loss: 0.1006 - accuracy: 0.9963\n",
      "Epoch 31/50\n",
      "141165/141165 [==============================] - 6s 41us/sample - loss: 0.0967 - accuracy: 0.9968\n",
      "Epoch 32/50\n",
      "141165/141165 [==============================] - 6s 40us/sample - loss: 0.0942 - accuracy: 0.9968\n",
      "Epoch 33/50\n",
      "141165/141165 [==============================] - 6s 41us/sample - loss: 0.0921 - accuracy: 0.9966\n",
      "Epoch 34/50\n",
      "141165/141165 [==============================] - 5s 38us/sample - loss: 0.0889 - accuracy: 0.9968\n",
      "Epoch 35/50\n",
      "141165/141165 [==============================] - 6s 40us/sample - loss: 0.0869 - accuracy: 0.9968\n",
      "Epoch 36/50\n",
      "141165/141165 [==============================] - 6s 42us/sample - loss: 0.0849 - accuracy: 0.9967\n",
      "Epoch 37/50\n",
      "141165/141165 [==============================] - 6s 40us/sample - loss: 0.0828 - accuracy: 0.9969\n",
      "Epoch 38/50\n",
      "141165/141165 [==============================] - 6s 40us/sample - loss: 0.0810 - accuracy: 0.9968\n",
      "Epoch 39/50\n",
      "141165/141165 [==============================] - 6s 44us/sample - loss: 0.0794 - accuracy: 0.9969\n",
      "Epoch 40/50\n",
      "141165/141165 [==============================] - 5s 39us/sample - loss: 0.0774 - accuracy: 0.9969\n",
      "Epoch 41/50\n",
      "141165/141165 [==============================] - 6s 40us/sample - loss: 0.0757 - accuracy: 0.9969\n",
      "Epoch 42/50\n",
      "141165/141165 [==============================] - 6s 42us/sample - loss: 0.0736 - accuracy: 0.9970\n",
      "Epoch 43/50\n",
      "141165/141165 [==============================] - 6s 39us/sample - loss: 0.0721 - accuracy: 0.9970\n",
      "Epoch 44/50\n",
      "141165/141165 [==============================] - 6s 39us/sample - loss: 0.0722 - accuracy: 0.9966\n",
      "Epoch 45/50\n",
      "141165/141165 [==============================] - 6s 43us/sample - loss: 0.0697 - accuracy: 0.9970\n",
      "Epoch 46/50\n",
      "141165/141165 [==============================] - 6s 40us/sample - loss: 0.0693 - accuracy: 0.9968\n",
      "Epoch 47/50\n",
      "141165/141165 [==============================] - 5s 39us/sample - loss: 0.0675 - accuracy: 0.9967\n",
      "Epoch 48/50\n",
      "141165/141165 [==============================] - 6s 39us/sample - loss: 0.0660 - accuracy: 0.9969\n",
      "Epoch 49/50\n",
      "141165/141165 [==============================] - 5s 39us/sample - loss: 0.0649 - accuracy: 0.9970\n",
      "Epoch 50/50\n",
      "141165/141165 [==============================] - 5s 39us/sample - loss: 0.0637 - accuracy: 0.9968\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x, y, batch_size=1000, epochs= 50, use_multiprocessing=True,verbose=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model,binarizer,dataset,triples):\n",
    "    x_=[]\n",
    "    y_=[]\n",
    "    \n",
    "    hits = []\n",
    "    ranks=[]\n",
    "    for i in range(10):\n",
    "        hits.append([])\n",
    "\n",
    "    rank_per_relation=dict()\n",
    "        \n",
    "    for i in triples:\n",
    "        s,p,o=i\n",
    "        x_.append((entitiy_idx[s],entitiy_idx[o]))\n",
    "        y_.append(p)\n",
    "    \n",
    "    \n",
    "    tensor_pred=torch.from_numpy(model.predict(np.array(x_)))\n",
    "    \n",
    "    _, ranked_predictions =tensor_pred.topk(k=len(binarizer.classes_))\n",
    "    \n",
    "    ranked_predictions=ranked_predictions.numpy()\n",
    "    \n",
    "    \n",
    "    assert len(ranked_predictions)==len(y_)\n",
    "    \n",
    "    classes_=binarizer.classes_.tolist()\n",
    "        \n",
    "    for i in range(len(y_)):\n",
    "        true_relation=y_[i]\n",
    "        ith_class=classes_.index(true_relation)\n",
    "        \n",
    "        rank = np.where(ranked_predictions[i]==ith_class)[0]\n",
    "        \n",
    "\n",
    "        rank_per_relation.setdefault(true_relation, []).append(rank+1)\n",
    "        \n",
    "        ranks.append(rank+1)\n",
    "        \n",
    "        for hits_level in range(10):\n",
    "            if rank <= hits_level:\n",
    "                hits[hits_level].append(1.0)\n",
    "    \n",
    "\n",
    "    hits=np.array(hits)\n",
    "    ranks=np.array(ranks)\n",
    "    print('########## Relation Prediction Results ##########')\n",
    "\n",
    "    print('Mean Hits @5: {0}'.format(sum(hits[4]) / (float(len(y_)))))\n",
    "    print('Mean Hits @3: {0}'.format(sum(hits[2]) / (float(len(y_)))))\n",
    "    print('Mean Hits @1: {0}'.format(sum(hits[0]) / (float(len(y_)))))\n",
    "    print('Mean rank: {0}'.format(np.mean(ranks)))\n",
    "    print('Mean reciprocal rank: {0}'.format(np.mean(1. / ranks)))\n",
    "    \n",
    "    print('########## Relation Prediction Analysis ##########')\n",
    "    \n",
    "    for pred, ranks in rank_per_relation.items():\n",
    "        ranks=np.array(ranks)\n",
    "        \n",
    "        average_hit_at_1=np.sum(ranks==1)/len(ranks)\n",
    "        average_hit_at_3=np.sum(ranks<=3)/len(ranks)\n",
    "        average_hit_at_5=np.sum(ranks<=5)/len(ranks)\n",
    "        \n",
    "        print('{0}:\\t Hits@1:\\t{1:.3f}'.format(pred,average_hit_at_1))\n",
    "        print('{0}:\\t Hits@3:\\t{1:.3f}'.format(pred,average_hit_at_3))\n",
    "        print('{0}:\\t Hits@5:\\t{1:.3f}'.format(pred,average_hit_at_5))\n",
    "        print('{0}:\\t MRR:\\t{1:.3f}\\t number of occurrence {2}'.format(pred,np.mean(1. / ranks),len(ranks)))\n",
    "        print('################################')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Relation Prediction Results ##########\n",
      "Mean Hits @5: 1.0\n",
      "Mean Hits @3: 0.9999929299642256\n",
      "Mean Hits @1: 0.997087145260955\n",
      "Mean rank: 1.0029411348821424\n",
      "Mean reciprocal rank: 0.9985394484429426\n",
      "########## Relation Prediction Analysis ##########\n",
      "_hyponym:\t Hits@1:\t0.998\n",
      "_hyponym:\t Hits@3:\t1.000\n",
      "_hyponym:\t Hits@5:\t1.000\n",
      "_hyponym:\t MRR:\t0.999\t number of occurrence 34832\n",
      "################################\n",
      "_hypernym:\t Hits@1:\t0.998\n",
      "_hypernym:\t Hits@3:\t1.000\n",
      "_hypernym:\t Hits@5:\t1.000\n",
      "_hypernym:\t MRR:\t0.999\t number of occurrence 34796\n",
      "################################\n",
      "_member_holonym:\t Hits@1:\t0.997\n",
      "_member_holonym:\t Hits@3:\t1.000\n",
      "_member_holonym:\t Hits@5:\t1.000\n",
      "_member_holonym:\t MRR:\t0.998\t number of occurrence 7382\n",
      "################################\n",
      "_derivationally_related_form:\t Hits@1:\t0.998\n",
      "_derivationally_related_form:\t Hits@3:\t1.000\n",
      "_derivationally_related_form:\t Hits@5:\t1.000\n",
      "_derivationally_related_form:\t MRR:\t0.999\t number of occurrence 29715\n",
      "################################\n",
      "_instance_hypernym:\t Hits@1:\t1.000\n",
      "_instance_hypernym:\t Hits@3:\t1.000\n",
      "_instance_hypernym:\t Hits@5:\t1.000\n",
      "_instance_hypernym:\t MRR:\t1.000\t number of occurrence 2921\n",
      "################################\n",
      "_also_see:\t Hits@1:\t0.978\n",
      "_also_see:\t Hits@3:\t1.000\n",
      "_also_see:\t Hits@5:\t1.000\n",
      "_also_see:\t MRR:\t0.989\t number of occurrence 1299\n",
      "################################\n",
      "_member_meronym:\t Hits@1:\t0.997\n",
      "_member_meronym:\t Hits@3:\t1.000\n",
      "_member_meronym:\t Hits@5:\t1.000\n",
      "_member_meronym:\t MRR:\t0.998\t number of occurrence 7402\n",
      "################################\n",
      "_member_of_domain_topic:\t Hits@1:\t0.990\n",
      "_member_of_domain_topic:\t Hits@3:\t1.000\n",
      "_member_of_domain_topic:\t Hits@5:\t1.000\n",
      "_member_of_domain_topic:\t MRR:\t0.995\t number of occurrence 3118\n",
      "################################\n",
      "_part_of:\t Hits@1:\t0.998\n",
      "_part_of:\t Hits@3:\t1.000\n",
      "_part_of:\t Hits@5:\t1.000\n",
      "_part_of:\t MRR:\t0.999\t number of occurrence 4805\n",
      "################################\n",
      "_instance_hyponym:\t Hits@1:\t0.999\n",
      "_instance_hyponym:\t Hits@3:\t1.000\n",
      "_instance_hyponym:\t Hits@5:\t1.000\n",
      "_instance_hyponym:\t MRR:\t1.000\t number of occurrence 2935\n",
      "################################\n",
      "_synset_domain_topic_of:\t Hits@1:\t0.989\n",
      "_synset_domain_topic_of:\t Hits@3:\t1.000\n",
      "_synset_domain_topic_of:\t Hits@5:\t1.000\n",
      "_synset_domain_topic_of:\t MRR:\t0.995\t number of occurrence 3116\n",
      "################################\n",
      "_has_part:\t Hits@1:\t0.997\n",
      "_has_part:\t Hits@3:\t1.000\n",
      "_has_part:\t Hits@5:\t1.000\n",
      "_has_part:\t MRR:\t0.998\t number of occurrence 4816\n",
      "################################\n",
      "_member_of_domain_usage:\t Hits@1:\t1.000\n",
      "_member_of_domain_usage:\t Hits@3:\t1.000\n",
      "_member_of_domain_usage:\t Hits@5:\t1.000\n",
      "_member_of_domain_usage:\t MRR:\t1.000\t number of occurrence 629\n",
      "################################\n",
      "_member_of_domain_region:\t Hits@1:\t0.995\n",
      "_member_of_domain_region:\t Hits@3:\t1.000\n",
      "_member_of_domain_region:\t Hits@5:\t1.000\n",
      "_member_of_domain_region:\t MRR:\t0.997\t number of occurrence 923\n",
      "################################\n",
      "_synset_domain_usage_of:\t Hits@1:\t1.000\n",
      "_synset_domain_usage_of:\t Hits@3:\t1.000\n",
      "_synset_domain_usage_of:\t Hits@5:\t1.000\n",
      "_synset_domain_usage_of:\t MRR:\t1.000\t number of occurrence 632\n",
      "################################\n",
      "_synset_domain_region_of:\t Hits@1:\t0.991\n",
      "_synset_domain_region_of:\t Hits@3:\t1.000\n",
      "_synset_domain_region_of:\t Hits@5:\t1.000\n",
      "_synset_domain_region_of:\t MRR:\t0.996\t number of occurrence 903\n",
      "################################\n",
      "_verb_group:\t Hits@1:\t0.977\n",
      "_verb_group:\t Hits@3:\t1.000\n",
      "_verb_group:\t Hits@5:\t1.000\n",
      "_verb_group:\t MRR:\t0.989\t number of occurrence 1138\n",
      "################################\n",
      "_similar_to:\t Hits@1:\t1.000\n",
      "_similar_to:\t Hits@3:\t1.000\n",
      "_similar_to:\t Hits@5:\t1.000\n",
      "_similar_to:\t MRR:\t1.000\t number of occurrence 80\n",
      "################################\n"
     ]
    }
   ],
   "source": [
    "evaluation(model,binarizer,dataset,dataset.train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Relation Prediction Results ##########\n",
      "Mean Hits @5: 0.9964\n",
      "Mean Hits @3: 0.9932\n",
      "Mean Hits @1: 0.9692\n",
      "Mean rank: 1.0836\n",
      "Mean reciprocal rank: 0.981476453709689\n",
      "########## Relation Prediction Analysis ##########\n",
      "_hypernym:\t Hits@1:\t0.969\n",
      "_hypernym:\t Hits@3:\t0.993\n",
      "_hypernym:\t Hits@5:\t0.996\n",
      "_hypernym:\t MRR:\t0.981\t number of occurrence 1174\n",
      "################################\n",
      "_derivationally_related_form:\t Hits@1:\t0.962\n",
      "_derivationally_related_form:\t Hits@3:\t0.991\n",
      "_derivationally_related_form:\t Hits@5:\t0.996\n",
      "_derivationally_related_form:\t MRR:\t0.977\t number of occurrence 1078\n",
      "################################\n",
      "_synset_domain_topic_of:\t Hits@1:\t1.000\n",
      "_synset_domain_topic_of:\t Hits@3:\t1.000\n",
      "_synset_domain_topic_of:\t Hits@5:\t1.000\n",
      "_synset_domain_topic_of:\t MRR:\t1.000\t number of occurrence 105\n",
      "################################\n",
      "_member_meronym:\t Hits@1:\t0.985\n",
      "_member_meronym:\t Hits@3:\t1.000\n",
      "_member_meronym:\t Hits@5:\t1.000\n",
      "_member_meronym:\t MRR:\t0.992\t number of occurrence 273\n",
      "################################\n",
      "_instance_hypernym:\t Hits@1:\t1.000\n",
      "_instance_hypernym:\t Hits@3:\t1.000\n",
      "_instance_hypernym:\t Hits@5:\t1.000\n",
      "_instance_hypernym:\t MRR:\t1.000\t number of occurrence 107\n",
      "################################\n",
      "_part_of:\t Hits@1:\t0.972\n",
      "_part_of:\t Hits@3:\t0.989\n",
      "_part_of:\t Hits@5:\t1.000\n",
      "_part_of:\t MRR:\t0.981\t number of occurrence 178\n",
      "################################\n",
      "_has_part:\t Hits@1:\t0.968\n",
      "_has_part:\t Hits@3:\t0.987\n",
      "_has_part:\t Hits@5:\t1.000\n",
      "_has_part:\t MRR:\t0.980\t number of occurrence 154\n",
      "################################\n",
      "_hyponym:\t Hits@1:\t0.968\n",
      "_hyponym:\t Hits@3:\t0.997\n",
      "_hyponym:\t Hits@5:\t0.998\n",
      "_hyponym:\t MRR:\t0.982\t number of occurrence 1236\n",
      "################################\n",
      "_member_holonym:\t Hits@1:\t0.985\n",
      "_member_holonym:\t Hits@3:\t1.000\n",
      "_member_holonym:\t Hits@5:\t1.000\n",
      "_member_holonym:\t MRR:\t0.991\t number of occurrence 268\n",
      "################################\n",
      "_synset_domain_region_of:\t Hits@1:\t0.976\n",
      "_synset_domain_region_of:\t Hits@3:\t1.000\n",
      "_synset_domain_region_of:\t Hits@5:\t1.000\n",
      "_synset_domain_region_of:\t MRR:\t0.988\t number of occurrence 42\n",
      "################################\n",
      "_member_of_domain_topic:\t Hits@1:\t0.973\n",
      "_member_of_domain_topic:\t Hits@3:\t1.000\n",
      "_member_of_domain_topic:\t Hits@5:\t1.000\n",
      "_member_of_domain_topic:\t MRR:\t0.987\t number of occurrence 112\n",
      "################################\n",
      "_instance_hyponym:\t Hits@1:\t1.000\n",
      "_instance_hyponym:\t Hits@3:\t1.000\n",
      "_instance_hyponym:\t Hits@5:\t1.000\n",
      "_instance_hyponym:\t MRR:\t1.000\t number of occurrence 107\n",
      "################################\n",
      "_verb_group:\t Hits@1:\t0.977\n",
      "_verb_group:\t Hits@3:\t0.977\n",
      "_verb_group:\t Hits@5:\t0.977\n",
      "_verb_group:\t MRR:\t0.980\t number of occurrence 43\n",
      "################################\n",
      "_also_see:\t Hits@1:\t0.683\n",
      "_also_see:\t Hits@3:\t0.829\n",
      "_also_see:\t Hits@5:\t0.854\n",
      "_also_see:\t MRR:\t0.777\t number of occurrence 41\n",
      "################################\n",
      "_synset_domain_usage_of:\t Hits@1:\t1.000\n",
      "_synset_domain_usage_of:\t Hits@3:\t1.000\n",
      "_synset_domain_usage_of:\t Hits@5:\t1.000\n",
      "_synset_domain_usage_of:\t MRR:\t1.000\t number of occurrence 23\n",
      "################################\n",
      "_member_of_domain_usage:\t Hits@1:\t1.000\n",
      "_member_of_domain_usage:\t Hits@3:\t1.000\n",
      "_member_of_domain_usage:\t Hits@5:\t1.000\n",
      "_member_of_domain_usage:\t MRR:\t1.000\t number of occurrence 22\n",
      "################################\n",
      "_member_of_domain_region:\t Hits@1:\t0.941\n",
      "_member_of_domain_region:\t Hits@3:\t1.000\n",
      "_member_of_domain_region:\t Hits@5:\t1.000\n",
      "_member_of_domain_region:\t MRR:\t0.971\t number of occurrence 34\n",
      "################################\n",
      "_similar_to:\t Hits@1:\t1.000\n",
      "_similar_to:\t Hits@3:\t1.000\n",
      "_similar_to:\t Hits@5:\t1.000\n",
      "_similar_to:\t MRR:\t1.000\t number of occurrence 3\n",
      "################################\n"
     ]
    }
   ],
   "source": [
    "evaluation(model,binarizer,dataset,dataset.valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Relation Prediction Results ##########\n",
      "Mean Hits @5: 0.9976\n",
      "Mean Hits @3: 0.9956\n",
      "Mean Hits @1: 0.9686\n",
      "Mean rank: 1.0716\n",
      "Mean reciprocal rank: 0.9815491295306001\n",
      "########## Relation Prediction Analysis ##########\n",
      "_member_of_domain_usage:\t Hits@1:\t1.000\n",
      "_member_of_domain_usage:\t Hits@3:\t1.000\n",
      "_member_of_domain_usage:\t Hits@5:\t1.000\n",
      "_member_of_domain_usage:\t MRR:\t1.000\t number of occurrence 24\n",
      "################################\n",
      "_verb_group:\t Hits@1:\t0.923\n",
      "_verb_group:\t Hits@3:\t0.974\n",
      "_verb_group:\t Hits@5:\t1.000\n",
      "_verb_group:\t MRR:\t0.954\t number of occurrence 39\n",
      "################################\n",
      "_hyponym:\t Hits@1:\t0.973\n",
      "_hyponym:\t Hits@3:\t0.996\n",
      "_hyponym:\t Hits@5:\t0.997\n",
      "_hyponym:\t MRR:\t0.984\t number of occurrence 1153\n",
      "################################\n",
      "_member_of_domain_region:\t Hits@1:\t0.962\n",
      "_member_of_domain_region:\t Hits@3:\t1.000\n",
      "_member_of_domain_region:\t Hits@5:\t1.000\n",
      "_member_of_domain_region:\t MRR:\t0.981\t number of occurrence 26\n",
      "################################\n",
      "_member_meronym:\t Hits@1:\t0.960\n",
      "_member_meronym:\t Hits@3:\t0.996\n",
      "_member_meronym:\t Hits@5:\t1.000\n",
      "_member_meronym:\t MRR:\t0.977\t number of occurrence 253\n",
      "################################\n",
      "_part_of:\t Hits@1:\t0.945\n",
      "_part_of:\t Hits@3:\t0.976\n",
      "_part_of:\t Hits@5:\t0.994\n",
      "_part_of:\t MRR:\t0.963\t number of occurrence 165\n",
      "################################\n",
      "_hypernym:\t Hits@1:\t0.978\n",
      "_hypernym:\t Hits@3:\t0.999\n",
      "_hypernym:\t Hits@5:\t0.999\n",
      "_hypernym:\t MRR:\t0.988\t number of occurrence 1251\n",
      "################################\n",
      "_has_part:\t Hits@1:\t0.930\n",
      "_has_part:\t Hits@3:\t0.988\n",
      "_has_part:\t Hits@5:\t0.994\n",
      "_has_part:\t MRR:\t0.959\t number of occurrence 172\n",
      "################################\n",
      "_derivationally_related_form:\t Hits@1:\t0.968\n",
      "_derivationally_related_form:\t Hits@3:\t0.996\n",
      "_derivationally_related_form:\t Hits@5:\t0.996\n",
      "_derivationally_related_form:\t MRR:\t0.982\t number of occurrence 1074\n",
      "################################\n",
      "_member_holonym:\t Hits@1:\t0.975\n",
      "_member_holonym:\t Hits@3:\t0.993\n",
      "_member_holonym:\t Hits@5:\t0.996\n",
      "_member_holonym:\t MRR:\t0.984\t number of occurrence 278\n",
      "################################\n",
      "_also_see:\t Hits@1:\t0.714\n",
      "_also_see:\t Hits@3:\t0.964\n",
      "_also_see:\t Hits@5:\t1.000\n",
      "_also_see:\t MRR:\t0.829\t number of occurrence 56\n",
      "################################\n",
      "_instance_hypernym:\t Hits@1:\t1.000\n",
      "_instance_hypernym:\t Hits@3:\t1.000\n",
      "_instance_hypernym:\t Hits@5:\t1.000\n",
      "_instance_hypernym:\t MRR:\t1.000\t number of occurrence 122\n",
      "################################\n",
      "_synset_domain_region_of:\t Hits@1:\t1.000\n",
      "_synset_domain_region_of:\t Hits@3:\t1.000\n",
      "_synset_domain_region_of:\t Hits@5:\t1.000\n",
      "_synset_domain_region_of:\t MRR:\t1.000\t number of occurrence 37\n",
      "################################\n",
      "_synset_domain_topic_of:\t Hits@1:\t0.991\n",
      "_synset_domain_topic_of:\t Hits@3:\t1.000\n",
      "_synset_domain_topic_of:\t Hits@5:\t1.000\n",
      "_synset_domain_topic_of:\t MRR:\t0.994\t number of occurrence 114\n",
      "################################\n",
      "_member_of_domain_topic:\t Hits@1:\t0.946\n",
      "_member_of_domain_topic:\t Hits@3:\t1.000\n",
      "_member_of_domain_topic:\t Hits@5:\t1.000\n",
      "_member_of_domain_topic:\t MRR:\t0.970\t number of occurrence 111\n",
      "################################\n",
      "_instance_hyponym:\t Hits@1:\t1.000\n",
      "_instance_hyponym:\t Hits@3:\t1.000\n",
      "_instance_hyponym:\t Hits@5:\t1.000\n",
      "_instance_hyponym:\t MRR:\t1.000\t number of occurrence 108\n",
      "################################\n",
      "_synset_domain_usage_of:\t Hits@1:\t1.000\n",
      "_synset_domain_usage_of:\t Hits@3:\t1.000\n",
      "_synset_domain_usage_of:\t Hits@5:\t1.000\n",
      "_synset_domain_usage_of:\t MRR:\t1.000\t number of occurrence 14\n",
      "################################\n",
      "_similar_to:\t Hits@1:\t1.000\n",
      "_similar_to:\t Hits@3:\t1.000\n",
      "_similar_to:\t Hits@5:\t1.000\n",
      "_similar_to:\t MRR:\t1.000\t number of occurrence 3\n",
      "################################\n"
     ]
    }
   ],
   "source": [
    "evaluation(model,binarizer,dataset,dataset.test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (shallom)",
   "language": "python",
   "name": "shallom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
